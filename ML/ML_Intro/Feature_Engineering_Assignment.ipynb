{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n"
      ],
      "metadata": {
        "id": "kjeDbAcd633H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Questions"
      ],
      "metadata": {
        "id": "ej6AzEAj6821"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. What is a parameter?\n",
        "\n",
        "In feature engineering a parameter is a variable to define a specific data of set of conditions\n",
        "\n",
        "###2.  What is correlation?\n",
        "\n",
        "Statistical relationship between two variables. It determines how towo variables move with respect to each other.\n",
        "Correlation can be positive, negative or no correlation\n",
        "\n",
        "### What does negative correlation mean?\n",
        "\n",
        "Negative correlation means when one variable tends to increase, the other one decreases.Study hours and number of errors in test are negatively correlated.\n",
        "\n",
        "###3.  Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine learning is a subset of AI, that finds the statistical patterns within the data. it learns from the data and improves the performance over the time without being specifically programmed for a specific task.\n",
        "Components are\n",
        "  - Data\n",
        "  - Algorithms\n",
        "  - Models\n",
        "  - Training\n",
        "  - Evaluation\n",
        "  - Features\n",
        "  - Validations\n",
        "  - Hyper parameters\n",
        "\n",
        "###4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "Loss value calcualtes the error betweeen actual value & the predicted value. based on the loss the model re configures its statistical patterns to produce more accurate output.\n",
        "\n",
        "It the loss value is less than a certain thresold then the model can be considered to have less accuracy.\n",
        "\n",
        "###5. What are continuous and categorical variables?\n",
        "Continuous variables are numerical variables that can take infinite number of possible values within a given range. Example - Height of students in a class\n",
        "\n",
        "Categorical variables represent distinct groups or categories. They cannot be expressed in terms of continuous numbers. Example - Gender, it has distinct groups Male & Female\n",
        "\n",
        "###6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "When categorical variables are missing we can take the mode value of the variable.\n",
        "\n",
        "We can encode the variable using techniques like Label encoding, One hot encoding,Binary encoding etc.\n",
        "\n",
        "###7. What do you mean by training and testing a dataset?\n",
        "\n",
        "The entire available data is separated into training and testing data set.\n",
        "Training data set is given to the model to recognize patterns and validate the patterns.\n",
        "Once the model is trained, test data set is used to test the model to check the error & accuracy\n",
        "\n",
        "###8.What is sklearn.preprocessing?\n",
        "\n",
        "It is a module inside scikit learn python library, that contains various utilities to preprocess and transform the data.\n",
        "example - OneHotEncoder, Standard sclaer etc.\n",
        "\n",
        "###9. What is a Test set?\n",
        "\n",
        "A subset of the overall dataset to evaluate the model performance. Generally 20-20% of the overall data is kept aside as test data. Which is never exposed to the model during the training phase.\n",
        "\n",
        "###10.  How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('target_column', axis=1)\n",
        "y = data['target_column']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "```\n",
        "\n",
        "### How do you approach a Machine Learning problem?\n",
        "\n",
        "- Define & understand the problem\n",
        "- Gather & explore the data\n",
        "- Perform Preprocessing of the data\n",
        "- Perform Feature engineeding\n",
        "- Select the model & train\n",
        "- Evaluate the model & tune the parameters\n",
        "- Deploy the model\n",
        "\n",
        "###11. Why do we have to perform EDA before fitting a model to the data?\n",
        "We need to perform EDA to\n",
        "- To understand the data\n",
        "- Idnetify quality issues int he data like missing values or imbalance\n",
        "- Understand the data relationships\n",
        "- Visualize the data\n",
        "- Get guidance related to model selection\n",
        "\n",
        "###12.  What is correlation?\n",
        "\n",
        "Statistical relationship between two variables. It determines how towo variables move with respect to each other.\n",
        "Correlation can be positive, negative or no correlation\n",
        "\n",
        "###13. What does negative correlation mean?\n",
        "\n",
        "Negative correlation means when one variable tends to increase, the other one decreases.Study hours and number of errors in test are negatively correlated.\n",
        "\n",
        "###14. How can you find correlation between variables in Python?\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "```\n",
        "\n",
        "###15. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Causation is a relationship where one event directly results in another event. Changes in one variable bring change in another variable.\n",
        "\n",
        "Example - Study might indicate that student with eye glasses perform better academically\n",
        "\n",
        "Correlation - This is a positive correlation between wearing glasses & academic performance.But this doesnot mean that  wearing glass only improves academic performance\n",
        "\n",
        "Causation - There may be underlying factor such as good vision correction or better eyesight or better reading abailities, that might increase the performance.\n",
        "\n",
        "###16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "Optimizer is an algorithm or method to adjust the parameters of a model to increase the aaccuracy or maximize a specific objective function.\n",
        "Optimizer finds the best set of parameters for the model.\n",
        "\n",
        "Gradien descent - When training a linear regression model to predict house prices. Gradient descent will iteratively adjust the model parameters to minimize the difference between the predicted and actual prices by following the slope (gradient) of the loss function.\n",
        "\n",
        "Stochastic Gradient Descent (SGD) - nstead of using the entire dataset to update the weights in our linear regression model, SGD uses one data point at a time, leading to faster updates but with more variability in the parameter updates.\n",
        "\n",
        "Mini-batch Gradient Descent - In the linear regression model, mini-batch gradient descent might use 32 data points at a time to update the model's parameters, striking a balance between computational efficiency and stability.\n",
        "\n",
        "Adam (Adaptive Moment Estimation) - In our linear regression model, Adam adjusts the learning rate for each parameter independently, leading to faster convergence and better performance even on noisy data.\n",
        "\n",
        "\n",
        "###17. What is sklearn.linear_model ?\n",
        "\n",
        "A module inside the scikit learn that provides various linear machine learning models for regression & classification.\n",
        "\n",
        "\n",
        "###18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "Trains a machine learning model on a given dataset.\n",
        "Arguments are training data & target data\n",
        "```\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "#input features (X) and target values (y)\n",
        "X = np.array([[2, 1500, 1], [3, 2000, 2], [4, 2500, 3], [2, 1800, 2]])\n",
        "y = np.array([300000, 400000, 500000, 350000])\n",
        "\n",
        "# Creating a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "#Training the model with training data (X) and target values (y)\n",
        "model.fit(X, y)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "###19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "After the model has been trained with model.fit(), model.predict() generates predictions for new input data.\n",
        "Argument is new input data\n",
        "```\n",
        "#New input features (X) for making predictions\n",
        "X_new = np.array([[3, 2200, 2]])\n",
        "\n",
        "#Making predictions\n",
        "predictions = model.predict(X_new)\n",
        "```\n",
        "\n",
        "###20. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables are numerical variables that can take infinite number of possible values within a given range. Example - Height of students in a class\n",
        "\n",
        "Categorical variables represent distinct groups or categories. They cannot be expressed in terms of continuous numbers. Example - Gender, it has distinct groups Male & Female\n",
        "\n",
        "###21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "A method to standaradize the range of feature variable values.\n",
        "Transforms the values of the feature without distorting the differences in the range of values.\n",
        "Benefits\n",
        "- Faster convergence\n",
        "- Improved performance\n",
        "- Prevents feature dominance due to large ranges\n",
        "\n",
        "###22.  How do we perform scaling in Python?\n",
        "\n",
        "Scaling can be done using scikit learn utilities  like standarad scaler, min max scaler etc.\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "#feature data\n",
        "data = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
        "\n",
        "#StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#Scaling\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Original Data:\\n\", data)\n",
        "print(\"Standardized Data:\\n\", scaled_data)\n",
        "\n",
        "``\n",
        "\n",
        "###23. What is sklearn.preprocessing?\n",
        "\n",
        "It is a module inside scikit learn python library, that contains various utilities to preprocess and transform the data. example - OneHotEncoder, Standard sclaer etc.\n",
        "\n",
        "\n",
        "###24.How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('target_column', axis=1)\n",
        "y = data['target_column']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "```\n",
        "\n",
        "###25.  Explain data encoding?\n",
        "\n",
        "Data encoding is a process of transforming categorical data into numerical format so that machine learning algorithms can understand and process it.\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data = [\"Low\", \"Medium\", \"High\", \"Medium\", \"Low\"]\n",
        "\n",
        "#label encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "#transforming the data\n",
        "encoded_data = encoder.fit_transform(data)\n",
        "\n",
        "print(\"Original Data:\", data)\n",
        "print(\"Label Encoded Data:\", encoded_data)\n",
        "```"
      ],
      "metadata": {
        "id": "QuTET9uZ7EWF"
      }
    }
  ]
}